{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "import csv\n",
    "ndtv = open(\"news_headlines_ndtv.csv\", \"a\") #opening a new csv file for ndtv headlines in append mode\n",
    "for i_ndtv in range(1,14):\n",
    "    headlines_ndtv = list()\n",
    "    page_ndtv = urllib.urlopen('http://www.ndtv.com/top-stories/page-'+str(i_ndtv)) #accessing different pages on ndtv website\n",
    "    soup_ndtv = BeautifulSoup(page_ndtv)\n",
    "    p_ndtv = soup_ndtv('div') #parsing wrt 'div' tag\n",
    "    hl_ndtv = soup_ndtv('a') #parsing wrt 'a' tag\n",
    "    for x_ndtv in p_ndtv:\n",
    "        for t_ndtv in hl_ndtv:\n",
    "            if (x_ndtv.get('class') == 'nstory_header'):  #parsing wrt 'class' attribute\n",
    "                if(str(t_ndtv.get('title')) != 'None'):\n",
    "                    if(str(t_ndtv.get('title'))!=\"Weddings\"):\n",
    "                        temp_ndtv = (str(t_ndtv.get('title'))).split(',')\n",
    "                        temp_concat_ndtv = ''\n",
    "                        for i in temp_ndtv:\n",
    "                            temp_concat_ndtv = i + ' '+temp_concat_ndtv\n",
    "                        headlines_ndtv.append(temp_concat_ndtv) #accessing the contents of 'title' attribute and storing in created list\n",
    "    \n",
    "    for l_ndtv in range(12,41): #accessing only the headlines in list and discarding garbage(wrt headlines)\n",
    "        if (l_ndtv%2==0):\n",
    "            ndtv.write(headlines_ndtv[l_ndtv]+'\\n') #storing into the created file\n",
    "            \n",
    "    #ndtv.write('\\n')\n",
    "    \n",
    "    \n",
    "ndtv.close()\n",
    "\n",
    "toi = open('news_headlines_toi.csv','a') #opening a new csv file for toi headlines in append mode\n",
    "headlines_toi=list()\n",
    "page_toi = urllib.urlopen('https://timesofindia.indiatimes.com/home/headlines')\n",
    "soup_toi = BeautifulSoup(page_toi)\n",
    "p_toi = soup_toi('div') #parsing wrt 'div' tag\n",
    "hl_toi = soup_toi('a') #parsing wrt 'a' tag\n",
    "for x_toi in p_toi:\n",
    "    for t_toi in hl_toi:\n",
    "        if (x_toi.get('class') == 'top-newslist'): #parsing wrt 'class' attribute\n",
    "            if(str(t_toi.get('title')) != 'None'):\n",
    "                temp_concat_toi = ''\n",
    "                temp_toi = (str(t_toi.get('title'))).split(',')\n",
    "                for i in temp_toi:\n",
    "                    temp_concat_toi = i + ' '+temp_concat_toi\n",
    "                headlines_toi.append(temp_concat_toi) #accessing the contents of 'title' attribute and stor\n",
    "\n",
    "                \n",
    "\n",
    "for i_toi in range (10,135): #accessing only the headlines in list and discarding garbage(wrt headlines)\n",
    "   toi.write(headlines_toi[i_toi]+'\\n') #storing into the created file\n",
    "toi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
